<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Analysis of Algorithms - Introduction to Programming Using Java</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="ferris.css">
        <link rel="stylesheet" href="theme/2018-edition.css">

<link rel="stylesheet" href="code-class.css">

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="title-page.html" >Introduction to Programming Using Java</a></li><li class="chapter-item expanded affix "><a href="preface.html">Preface</a></li><li class="chapter-item expanded "><a href="ch01-00-Overview.html"><strong aria-hidden="true">1.</strong> Overview</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch01-01-FetchExecuteCycle.html"><strong aria-hidden="true">1.1.</strong> Fetch and Execute Cycle</a></li><li class="chapter-item expanded "><a href="ch01-02-AsynchronousEvents.html"><strong aria-hidden="true">1.2.</strong> Asynchronous Events</a></li><li class="chapter-item expanded "><a href="ch01-03-JavaVirtualMachine.html"><strong aria-hidden="true">1.3.</strong> The Java Virtual Machine</a></li><li class="chapter-item expanded "><a href="ch01-04-FundamentalBuildingBlocks.html"><strong aria-hidden="true">1.4.</strong> Fundamentals</a></li><li class="chapter-item expanded "><a href="ch01-05-OOP.html"><strong aria-hidden="true">1.5.</strong> Object Oriented Programming</a></li><li class="chapter-item expanded "><a href="ch01-06-ModernUserInterface.html"><strong aria-hidden="true">1.6.</strong> Modern User Interface</a></li><li class="chapter-item expanded "><a href="ch01-07-InternetAndBeyond.html"><strong aria-hidden="true">1.7.</strong> Internet and Beyond</a></li><li class="chapter-item expanded "><a href="ch01-08-Quiz.html"><strong aria-hidden="true">1.8.</strong> Quiz</a></li></ol></li><li class="chapter-item expanded "><a href="ch02-00-NameAndThings.html"><strong aria-hidden="true">2.</strong> Name and Things</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch02-01-BasicJavaApplication.html"><strong aria-hidden="true">2.1.</strong> Basic Java Application</a></li><li class="chapter-item expanded "><a href="ch02-02-VariablesAndTypes.html"><strong aria-hidden="true">2.2.</strong> Variables and Types</a></li><li class="chapter-item expanded "><a href="ch02-03-ObjectsAndSubroutines.html"><strong aria-hidden="true">2.3.</strong> Objects and Subroutines</a></li><li class="chapter-item expanded "><a href="ch02-04-TextInputAndOutput.html"><strong aria-hidden="true">2.4.</strong> Text Input and Output</a></li><li class="chapter-item expanded "><a href="ch02-05-DetailsOfExpressions.html"><strong aria-hidden="true">2.5.</strong> Details of Expressions</a></li><li class="chapter-item expanded "><a href="ch02-06-ProgrammingEnvironments.html"><strong aria-hidden="true">2.6.</strong> Programming and Environments</a></li><li class="chapter-item expanded "><a href="ch02-07-Exercises.html"><strong aria-hidden="true">2.7.</strong> Exercises</a></li><li class="chapter-item expanded "><a href="ch02-08-Quiz.html"><strong aria-hidden="true">2.8.</strong> Quiz</a></li></ol></li><li class="chapter-item expanded "><a href="ch03-00-Control.html"><strong aria-hidden="true">3.</strong> Control</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch03-01-BlocksLoopsBranches.html"><strong aria-hidden="true">3.1.</strong> Blocks, Loops and Branches</a></li><li class="chapter-item expanded "><a href="ch03-02-AlgorithmDevelopment.html"><strong aria-hidden="true">3.2.</strong> Algorithm Development</a></li><li class="chapter-item expanded "><a href="ch03-03-While.html"><strong aria-hidden="true">3.3.</strong> while and do...while</a></li><li class="chapter-item expanded "><a href="ch03-04-For.html"><strong aria-hidden="true">3.4.</strong> The for statement</a></li><li class="chapter-item expanded "><a href="ch03-05-If.html"><strong aria-hidden="true">3.5.</strong> The If Statement</a></li><li class="chapter-item expanded "><a href="ch03-06-Switch.html"><strong aria-hidden="true">3.6.</strong> The Switch Statement</a></li><li class="chapter-item expanded "><a href="ch03-07-ExceptionsTryCatch.html"><strong aria-hidden="true">3.7.</strong> Exceptions and try...catch</a></li><li class="chapter-item expanded "><a href="ch03-08-Arrays.html"><strong aria-hidden="true">3.8.</strong> Arrays: An Introduction</a></li><li class="chapter-item expanded "><a href="ch03-09-GUI.html"><strong aria-hidden="true">3.9.</strong> GUI: An Introduction</a></li><li class="chapter-item expanded "><a href="ch03-10-Exercises.html"><strong aria-hidden="true">3.10.</strong> Exercises</a></li><li class="chapter-item expanded "><a href="ch03-11-Quiz.html"><strong aria-hidden="true">3.11.</strong> Quiz</a></li></ol></li><li class="chapter-item expanded "><a href="ch04-00-Subroutines.html"><strong aria-hidden="true">4.</strong> Subroutines</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch04-01-BlackBoxes.html"><strong aria-hidden="true">4.1.</strong> Black Boxes</a></li><li class="chapter-item expanded "><a href="ch04-02-StaticSubroutines.html"><strong aria-hidden="true">4.2.</strong> Static Subroutines and Variables</a></li><li class="chapter-item expanded "><a href="ch04-03-Parameters.html"><strong aria-hidden="true">4.3.</strong> Parameters</a></li><li class="chapter-item expanded "><a href="ch04-04-ReturnValues.html"><strong aria-hidden="true">4.4.</strong> Return Values</a></li><li class="chapter-item expanded "><a href="ch04-05-Lambda.html"><strong aria-hidden="true">4.5.</strong> Lambda Expressions</a></li><li class="chapter-item expanded "><a href="ch04-06-APIPackagesModulesJavadoc.html"><strong aria-hidden="true">4.6.</strong> API, Packages, Modules and Javadoc</a></li><li class="chapter-item expanded "><a href="ch04-07-MoreOnProgramDesign.html"><strong aria-hidden="true">4.7.</strong> More on Program Design</a></li><li class="chapter-item expanded "><a href="ch04-08-TruthAboutDeclarations.html"><strong aria-hidden="true">4.8.</strong> Truth about Declarations</a></li><li class="chapter-item expanded "><a href="ch04-09-Exercises.html"><strong aria-hidden="true">4.9.</strong> Exercises</a></li><li class="chapter-item expanded "><a href="ch04-10-Quiz.html"><strong aria-hidden="true">4.10.</strong> Quiz</a></li></ol></li><li class="chapter-item expanded "><a href="ch05-00-ObjectsClasses.html"><strong aria-hidden="true">5.</strong> Objects and Classes</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch05-01-ObjectsAndInstanceMethods.html"><strong aria-hidden="true">5.1.</strong> Objects and Instance Methods</a></li><li class="chapter-item expanded "><a href="ch05-02-ConstructorObjectInit.html"><strong aria-hidden="true">5.2.</strong> Constructor and Object Initialization</a></li><li class="chapter-item expanded "><a href="ch05-03-ProgrammingWithObjects.html"><strong aria-hidden="true">5.3.</strong> Programming with Objects</a></li><li class="chapter-item expanded "><a href="ch05-04-AnExample.html"><strong aria-hidden="true">5.4.</strong> An Example</a></li><li class="chapter-item expanded "><a href="ch05-05-InheritanceAndPolymorphism.html"><strong aria-hidden="true">5.5.</strong> Inheritance and Polymorphism</a></li><li class="chapter-item expanded "><a href="ch05-06-thisandsuper.html"><strong aria-hidden="true">5.6.</strong> this and super</a></li><li class="chapter-item expanded "><a href="ch05-07-Interfaces.html"><strong aria-hidden="true">5.7.</strong> Interfaces</a></li><li class="chapter-item expanded "><a href="ch05-08-NestedClasses.html"><strong aria-hidden="true">5.8.</strong> Nested Classes</a></li><li class="chapter-item expanded "><a href="ch05-09-Exercises.html"><strong aria-hidden="true">5.9.</strong> Exercises</a></li><li class="chapter-item expanded "><a href="ch05-10-Quiz.html"><strong aria-hidden="true">5.10.</strong> Quiz</a></li></ol></li><li class="chapter-item expanded "><a href="ch06-00-GUIProgramming.html"><strong aria-hidden="true">6.</strong> Introduction to GUI Programming</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch06-01-BasicJavaFXApp.html"><strong aria-hidden="true">6.1.</strong> A Basic JavaFX Application</a></li><li class="chapter-item expanded "><a href="ch06-02-BasicClasses.html"><strong aria-hidden="true">6.2.</strong> Basic Classes</a></li><li class="chapter-item expanded "><a href="ch06-03-BasicEvents.html"><strong aria-hidden="true">6.3.</strong> Basic Events</a></li><li class="chapter-item expanded "><a href="ch06-04-BasicControls.html"><strong aria-hidden="true">6.4.</strong> Basic Controls</a></li><li class="chapter-item expanded "><a href="ch06-05-BasicLayout.html"><strong aria-hidden="true">6.5.</strong> Basic Layout</a></li><li class="chapter-item expanded "><a href="ch06-06-CompetePrograms.html"><strong aria-hidden="true">6.6.</strong> Complete Programs</a></li><li class="chapter-item expanded "><a href="ch06-07-Exercises.html"><strong aria-hidden="true">6.7.</strong> Exercises</a></li><li class="chapter-item expanded "><a href="ch06-08-Quiz.html"><strong aria-hidden="true">6.8.</strong> Quiz</a></li></ol></li><li class="chapter-item expanded "><a href="ch07-00-ArraysArraylistsRecords.html"><strong aria-hidden="true">7.</strong> Arrays, ArrayLists and Records</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch07-01-ArrayDetails.html"><strong aria-hidden="true">7.1.</strong> Array Details</a></li><li class="chapter-item expanded "><a href="ch07-02-ArrayProcessing.html"><strong aria-hidden="true">7.2.</strong> Array Processing</a></li><li class="chapter-item expanded "><a href="ch07-03-ArrayLists.html"><strong aria-hidden="true">7.3.</strong> ArrayLists</a></li><li class="chapter-item expanded "><a href="ch07-04-Records.html"><strong aria-hidden="true">7.4.</strong> Records</a></li><li class="chapter-item expanded "><a href="ch07-05-SearchingAndSorting.html"><strong aria-hidden="true">7.5.</strong> Searching and Sorting</a></li><li class="chapter-item expanded "><a href="ch07-06-2DArrays.html"><strong aria-hidden="true">7.6.</strong> 2D Arrays</a></li><li class="chapter-item expanded "><a href="ch07-07-Exercises.html"><strong aria-hidden="true">7.7.</strong> Exercises</a></li><li class="chapter-item expanded "><a href="ch07-08-Quiz.html"><strong aria-hidden="true">7.8.</strong> Quiz</a></li></ol></li><li class="chapter-item expanded "><a href="ch08-00-CorrectnessRobustnessEfficiency.html"><strong aria-hidden="true">8.</strong> Correctness, Robustness, Efficiency</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch08-01-IntroductionCorrectnessandRobustness.html"><strong aria-hidden="true">8.1.</strong> Introduction to Correctness and Robustness</a></li><li class="chapter-item expanded "><a href="ch08-02-WritingCorrectPrograms.html"><strong aria-hidden="true">8.2.</strong> Writing Correct Programs</a></li><li class="chapter-item expanded "><a href="ch08-03-ExceptionsAndtrycatch.html"><strong aria-hidden="true">8.3.</strong> Exceptions and try..catch</a></li><li class="chapter-item expanded "><a href="ch08-04-AssertionsAnnotations.html"><strong aria-hidden="true">8.4.</strong> Assertions and Annotations</a></li><li class="chapter-item expanded "><a class="active" href="ch08-05-AnalysisofAlgorithms.html"><strong aria-hidden="true">8.5.</strong> Analysis of Algorithms</a></li><li class="chapter-item expanded "><a href="ch08-06-Exercises.html"><strong aria-hidden="true">8.6.</strong> Exercises</a></li><li class="chapter-item expanded "><a href="ch08-07-Quiz.html"><strong aria-hidden="true">8.7.</strong> Quiz</a></li></ol></li><li class="chapter-item expanded "><a href="ch09-00-LinkedDataStructuresRecursion.html"><strong aria-hidden="true">9.</strong> Linked Data Structures and Recursion</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch09-01-Recursion.html"><strong aria-hidden="true">9.1.</strong> Recursion</a></li><li class="chapter-item expanded "><a href="ch09-02-LinkedDataStructures.html"><strong aria-hidden="true">9.2.</strong> Linked Data Structures</a></li><li class="chapter-item expanded "><a href="ch09-03-StacksQueuesADTs.html"><strong aria-hidden="true">9.3.</strong> Stacks, Queues and ADTs</a></li><li class="chapter-item expanded "><a href="ch09-04-BinaryTrees.html"><strong aria-hidden="true">9.4.</strong> Binary Trees</a></li><li class="chapter-item expanded "><a href="ch09-05-SimpleRecursiveDescentParser.html"><strong aria-hidden="true">9.5.</strong> A Simple Recursive Descent Parser</a></li><li class="chapter-item expanded "><a href="ch09-06-Exercises.html"><strong aria-hidden="true">9.6.</strong> Exercises</a></li><li class="chapter-item expanded "><a href="ch09-07-Quiz.html"><strong aria-hidden="true">9.7.</strong> Quiz</a></li></ol></li><li class="chapter-item expanded "><a href="ch10-00-GenericProgrammingandCollectionClasses.html"><strong aria-hidden="true">10.</strong> Generic Programmingand Collection Classes</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch10-01-GenericProgramming.html"><strong aria-hidden="true">10.1.</strong> Generic Programming</a></li><li class="chapter-item expanded "><a href="ch10-02-ListsandSets.html"><strong aria-hidden="true">10.2.</strong> Lists and Sets</a></li><li class="chapter-item expanded "><a href="ch10-03-Maps.html"><strong aria-hidden="true">10.3.</strong> Maps</a></li><li class="chapter-item expanded "><a href="ch10-04-JCF.html"><strong aria-hidden="true">10.4.</strong> Programming with the JCF</a></li><li class="chapter-item expanded "><a href="ch10-05-WritingGenericClassesandMethods.html"><strong aria-hidden="true">10.5.</strong> Writing Generic Classes and Methods</a></li><li class="chapter-item expanded "><a href="ch10-06-StreamAPI.html"><strong aria-hidden="true">10.6.</strong> Stream APIs</a></li><li class="chapter-item expanded "><a href="ch10-07-Exercises.html"><strong aria-hidden="true">10.7.</strong> Exercises</a></li><li class="chapter-item expanded "><a href="ch10-08-Quiz.html"><strong aria-hidden="true">10.8.</strong> Quiz</a></li></ol></li><li class="chapter-item expanded "><a href="ch11-00-IOStreamsFilesNetworking.html"><strong aria-hidden="true">11.</strong> I/O Streams, Files, and Networking</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch11-01-IOStreamsReadersAndWriters.html"><strong aria-hidden="true">11.1.</strong> I/O Streams, Readers, and Writers</a></li><li class="chapter-item expanded "><a href="ch11-02-Files.html"><strong aria-hidden="true">11.2.</strong> Files</a></li><li class="chapter-item expanded "><a href="ch11-03-ProgrammingWithFiles.html"><strong aria-hidden="true">11.3.</strong> Programming With Files</a></li><li class="chapter-item expanded "><a href="ch11-04-Networking.html"><strong aria-hidden="true">11.4.</strong> Networking</a></li><li class="chapter-item expanded "><a href="ch11-05-XML.html"><strong aria-hidden="true">11.5.</strong> A Brief Introduction to XML</a></li><li class="chapter-item expanded "><a href="ch11-06-Exercises.html"><strong aria-hidden="true">11.6.</strong> Exercises</a></li><li class="chapter-item expanded "><a href="ch11-07-Quiz.html"><strong aria-hidden="true">11.7.</strong> Quiz</a></li></ol></li><li class="chapter-item expanded "><a href="ch12-00-ThreadsandMultiprocessing.html"><strong aria-hidden="true">12.</strong> Threads and Multiprocessing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch12-01-IntroductiontoThreads.html"><strong aria-hidden="true">12.1.</strong> Introduction to Threads</a></li><li class="chapter-item expanded "><a href="ch12-02-ProgrammingwithThreads.html"><strong aria-hidden="true">12.2.</strong> Programming with Threads</a></li><li class="chapter-item expanded "><a href="ch12-03-ThreadsandParallelProcessing.html"><strong aria-hidden="true">12.3.</strong> Threads and Networking</a></li><li class="chapter-item expanded "><a href="ch12-04-ThreadsandNetworking.html"><strong aria-hidden="true">12.4.</strong> Threads and Networking</a></li><li class="chapter-item expanded "><a href="ch12-05-NetworkProgrammingExample.html"><strong aria-hidden="true">12.5.</strong> Network Programming Example</a></li><li class="chapter-item expanded "><a href="ch12-06-Exercises.html"><strong aria-hidden="true">12.6.</strong> Exercises</a></li><li class="chapter-item expanded "><a href="ch12-07-Quiz.html"><strong aria-hidden="true">12.7.</strong> Quiz</a></li></ol></li><li class="chapter-item expanded "><a href="ch13-00-GUIProgrammingContinued.html"><strong aria-hidden="true">13.</strong> GUI Programming Continued</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="ch13-01-PropertiesandBindings.html"><strong aria-hidden="true">13.1.</strong> Properties and Bindings</a></li><li class="chapter-item expanded "><a href="ch13-02-FancierGraphics.html"><strong aria-hidden="true">13.2.</strong> Fancier Graphics</a></li><li class="chapter-item expanded "><a href="ch13-03-ComplexComponentsandMVC.html"><strong aria-hidden="true">13.3.</strong> Complex Components and MVC</a></li><li class="chapter-item expanded "><a href="ch13-04-MostlyWindowsandDialogs.html"><strong aria-hidden="true">13.4.</strong> Mostly Windows and Dialogs</a></li><li class="chapter-item expanded "><a href="ch13-05-FinishingTouches.html"><strong aria-hidden="true">13.5.</strong> Finishing Touches</a></li><li class="chapter-item expanded "><a href="ch13-06-Exercises.html"><strong aria-hidden="true">13.6.</strong> Exercises</a></li><li class="chapter-item expanded "><a href="ch13-07-Quiz.html"><strong aria-hidden="true">13.7.</strong> Quiz</a></li></ol><li class="chapter-item expanded "><a href="appendix-00.html"> Appendix</a></li><li class="chapter-item expanded "><a href="glossary-00.html"> Glossary</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="Java">Java</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Introduction to Programming Using Java</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/Xayarsh/Java-book" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h2 id="Analysis of Algorithms"><a class="header" href="#Analysis of Algorithms">Analysis of Algorithms</a></h2>
                        <p>
                            This chapter has concentrated mostly on
                            correctness of programs.  In practice, another issue
                            is also important: <span class="newword">efficiency</span>.  When analyzing a
                            program in terms of efficiency, we want to look at questions such
                            as, "How long does it take for the program to run?" and "Is there
                            another approach that will get the answer more quickly?"
                            Efficiency will always be less important than correctness; if you
                            don't care whether a program works correctly, you can make it run
                            very quickly indeed, but no one will think it's much of an
                            achievement!  On the other hand, a program that gives a correct
                            answer after ten thousand years isn't very useful either, so
                            efficiency is often an important issue.</p>


                        <p>The term "efficiency" can refer to efficient use of almost any
                            resource, including time, computer memory, disk space, or network
                            bandwidth.  In this section, however, we will deal exclusively with
                            time efficiency, and the major question that we want to ask about
                            a program is, how long does it take to perform its task?</p>


                        <p>It really makes little sense to classify an individual program
                            as being "efficient" or "inefficient."  It makes more sense to
                            compare two (correct) programs that perform the same task and ask
                            which one of the two is "more efficient," that is, which one
                            performs the task more quickly.  However, even here there are
                            difficulties.  The running time of a program is not well-defined.
                            The run time can be different depending on the number and speed of the
                            processors in the computer on which it is run and, in the case of Java,
                            on the design of the Java Virtual Machine which is used to interpret
                            the program.  It can depend on details of the compiler which is
                            used to translate the program from high-level language to machine
                            language.  Furthermore, the run time of a program depends on
                            the size of the problem which the program has to solve.  It takes
                            a sorting program longer to sort 10000 items than it takes it
                            to sort 100 items.  When the run times of two programs are
                            compared, it often happens that Program&nbsp;A solves small problems
                            faster than Program&nbsp;B, while Program&nbsp;B solves large problems
                            faster than Program&nbsp;A, so that it is simply not the case that one
                            program is faster than the other in all cases.</p>


                        <p>In spite of these difficulties, there is a field of computer science
                            dedicated to analyzing the efficiency of programs.  The field is
                            known as <span class="newword">Analysis of Algorithms</span>.  The focus is
                            on algorithms, rather than on programs as such, to avoid having
                            to deal with multiple implementations of the same algorithm written
                            in different languages, compiled with different compilers, and running
                            on different computers.  Analysis of Algorithms is a mathematical
                            field that abstracts away from these down-and-dirty details.
                            Still, even though it is a theoretical field, every working programmer
                            should be aware of some of its techniques and results.  This section
                            is a very brief introduction to some of those techniques and results.
                            Because this is not a mathematics book, the treatment will be
                            rather informal.</p>


                        <p>One of the main techniques of analysis of algorithms is
                            <span class="newword">asymptotic analysis</span>.  The term "asymptotic"
                            here means basically "the tendency in the long run, as the size of
                            the input is increased."  An asymptotic
                            analysis of an algorithm's run time looks at the question of how
                            the run time depends on the size of the problem.  The analysis is
                            asymptotic because it only considers what happens to the run time
                            as the size of the problem increases without limit; it is not
                            concerned with what happens for problems of small size or, in fact,
                            for problems of any fixed finite size.  Only what happens in the
                            long run, as the problem size increases without limit, is important.
                            Showing that Algorithm&nbsp;A is asymptotically faster than
                            Algorithm&nbsp;B doesn't necessarily mean that Algorithm&nbsp;A will
                            run faster than Algorithm&nbsp;B for problems of size 10 or size
                            1000 or even size 1000000&mdash;it only means that if you keep
                            increasing the problem size, you will eventually come to a point
                            where Algorithm&nbsp;A is faster than Algorithm&nbsp;B.  An asymptotic
                            analysis is only a first approximation, but in practice it often
                            gives important and useful information.</p>

                        
                        <p>Central to asymptotic analysis is <span class="newword">Big-Oh notation</span>.
                            Using this notation, we might say, for example, that an algorithm has a running time
                            that is O(n<sup>2</sup>) or O(n) or O(log(n)).  These notations
                            are read "Big-Oh of n squared," "Big-Oh of n," and "Big-Oh of log&nbsp;n"
                            (where log is a logarithm function).  More generally, we can refer to
                            O(f(n)) ("Big-Oh of f of&nbsp;n"), where f(n) is some function that
                            assigns a positive real number to every positive integer&nbsp;n.  The "n"
                            in this notation refers to the size of the problem.  Before you can even
                            begin an asymptotic analysis, you need some way to measure problem size.
                            Usually, this is not a big issue.  For example, if the problem is to
                            sort a list of items, then the problem size can be taken to be the number of
                            items in the list.  When the input to an algorithm is an integer, as in
                            the case of an algorithm that checks whether a given positive integer is prime,
                            the usual measure of the size of a problem is the number of bits in the
                            input integer rather than the integer itself.  More generally, the number
                            of bits in the input to a problem is often a good measure of the size
                            of the problem.</p>


                        <p>To say that the running time of an algorithm is O(f(n)) means that
                            for large values of the problem size, n, the running time of the algorithm
                            is no bigger than some constant times f(n).  (More rigorously, there is a
                            number C and a positive integer M such that whenever n is greater than M,
                            the run time is less than or equal to C*f(n).)  The constant takes into
                            account details such as the speed of the computer on which the algorithm
                            is run; if you use a slower computer, you might have to use a bigger constant
                            in the formula, but changing the constant won't change the basic fact that the
                            run time is O(f(n)).  The constant also makes it unnecessary to say
                            whether we are measuring time in seconds, years, CPU cycles, or any other
                            unit of measure; a change from one unit of measure to another is just
                            multiplication by a constant.  Note also that O(f(n)) doesn't depend at
                            all on what happens for small problem sizes, only on what happens in the
                            long run as the problem size increases without limit.</p>


                        <p>To look at a simple example, consider the problem of adding up all
                            the numbers in an array.  The problem size, n, is the length of the array.
                            Using <span class="code">A</span> as the name of the array, the algorithm can be expressed in Java as:</p>


                        <pre><code class="java">total = 0;
for (int i = 0; i &lt; n; i++)
   total = total + A[i];</code></pre>


                        <p>This algorithm performs the same operation, <span class="code">total = total + A[i]</span>,
                            n&nbsp;times.  The total time spent on this operation is a*n, where a is the
                            time it takes to perform the operation once.  Now, this is not the only thing
                            that is done in the algorithm.  The value of <span class="code">i</span> is incremented and
                            is compared to n each time through the loop.  This adds an additional
                            time of b*n to the run time, for some constant&nbsp;b.  Furthermore, <span class="code">i</span> and
                            <span class="code">total</span> both have to be initialized to zero; this adds some constant
                            amount c to the running time.  The exact running time would then be
                            (a+b)*n+c, where the constants a, b, and c depend on factors such as how the
                            code is compiled and what computer it is run on.  Using the fact that c is less than
                            or equal to c*n for any positive integer n, we can say that the run time
                            is less than or equal to (a+b+c)*n.  That is, the run time is less than or equal
                            to a constant times n.  By definition, this means that the run time for this
                            algorithm is O(n).</p>


                        <p>If this explanation is too mathematical for you, we can just note that for large
                            values of n, the c in the formula (a+b)*n+c is insignificant compared to the other
                            term, (a+b)*n.  We say that c is a "lower order term."  When doing asymptotic analysis,
                            lower order terms can be discarded.  A rough, but correct, asymptotic analysis of
                            the algorithm would go something like this:  Each iteration of the <span class="code">for</span>
                            loop takes a certain constant amount of time.  There are n iterations of the loop,
                            so the total run time is a constant times n, plus lower order terms (to account
                            for the initialization).  Disregarding lower order terms, we see that the
                            run time is O(n).</p>





                        <p>Note that to say that an algorithm has run time O(f(n)) is to say that its
                            run time is no bigger than some constant times f(n) (for large values of n).  O(f(n)) puts
                            an <b>upper limit</b> on the run time.  However, the run time could be smaller,
                            even much smaller.  For example, if the run time is O(n), it would also be
                            correct to say that the run time is O(n<sup>2</sup>) or even O(n<sup>10</sup>).
                            If the run time is less than a constant times n, then it is certainly less than the
                            same constant times n<sup>2</sup> or n<sup>10</sup>.</p>


                        <p>Of course, sometimes it's useful to have a <b>lower limit</b> on the run time.
                            That is, we want to be able to say that the run time is greater than or equal to
                            some constant times f(n) (for large values of n).  The notation for this
                            is Ω(f(n)), read "Omega of f of&nbsp;n" or "Big Omega of f of&nbsp;n."
                            "Omega" is the name of a letter
                            in the Greek alphabet, and Ω is the upper case version of that letter.
                            (To be technical, saying that the run time of an algorithm is Ω(f(n)) means that
                            there is a positive number C and a positive integer M such that whenever n is greater than M,
                            the run time is greater than or equal to C*f(n).)  O(f(n)) tells you something
                            about the maximum amount of time that you might have to wait for an algorithm to
                            finish; Ω(f(n)) tells you something about the minimum time.</p>


                        <p>The algorithm for adding up the numbers in an array has a run time that
                            is Ω(n) as well as O(n).  When an algorithm has a run time that is
                            both Ω(f(n)) and O(f(n)), its run time is said to be Θ(f(n)),
                            read "Theta of f of&nbsp;n" or "Big Theta of f of&nbsp;n."
                            (Theta is another letter from the Greek alphabet.)
                            To say that the run time of an algorithm is Θ(f(n)) means that for large
                            values of n, the run time is between a*f(n) and b*f(n), where a and b are constants
                            (with b greater than&nbsp;a, and both greater than&nbsp;0).</p>


                        <p>Let's look at another example.  Consider the algorithm that can be expressed in Java
                            in the following method:</p>


                        <pre><code class="java">/**
 * Sorts the n array elements A[0], A[1], ..., A[n-1] into increasing order.
 */
public static void simpleBubbleSort( int[] A, int n ) {
   for (int i = 0; i &lt; n; i++) {
         // Do n passes through the array...
      for (int j = 0; j &lt; n-1; j++) {
         if ( A[j] &gt; A[j+1] ) {
                // A[j] and A[j+1] are out of order, so swap them
             int temp = A[j];
             A[j] = A[j+1];
             A[j+1] = temp;
         }
      }
   }
}</code></pre>


                        <p>Here, the parameter n represents the problem size.  The outer <span class="code">for</span>
                            loop in the method is executed n times.  Each time the outer <span class="code">for</span> loop
                            is executed, the inner <span class="code">for</span> loop is executed n-1 times, so the <span class="code">if</span>
                            statement is executed n*(n-1) times.  This is n<sup>2</sup>-n, but since lower order
                            terms are not significant in an asymptotic analysis, it's good enough to say that
                            the <span class="code">if</span> statement is executed about n<sup>2</sup> times.  In particular,
                            the test <span class="code">A[j]&nbsp;&gt;&nbsp;A[j+1]</span> is executed about n<sup>2</sup> times,
                            and this fact by itself is enough to say that the run time of the algorithm is
                            Ω(n<sup>2</sup>), that is, the run time is at least some constant times
                            n<sup>2</sup>.  Furthermore, if we look at other operations&mdash;the assignment
                            statements, incrementing <span class="code">i</span> and <span class="code">j</span>, etc.&mdash;none
                            of them are executed more than n<sup>2</sup> times, so the run time is also
                            O(n<sup>2</sup>), that is, the run time is no more than some constant
                            times n<sup>2</sup>.  Since it is both Ω(n<sup>2</sup>) and O(n<sup>2</sup>),
                            the run time of the simpleBubbleSort algorithm is Θ(n<sup>2</sup>).</p>


                        <p>You should be aware that some people use the notation O(f(n)) as if
                            it meant Θ(f(n)).  That is, when they say that the run time of an algorithm
                            is O(f(n)), they mean to say that the run time is about <b>equal</b> to
                            a constant times f(n).  For that, they should use Θ(f(n)).  Properly
                            speaking, O(f(n)) means that the run time is less than a constant times
                            f(n), possibly much less.</p>





                        <p>So far, my analysis has ignored an important detail.  We have looked at how run time
                            depends on the problem size, but in fact the run time usually depends not just on the
                            size of the problem but on the specific data that has to be processed.  For example, the
                            run time of a sorting algorithm can depend on the initial order of the items that are
                            to be sorted, and not just on the number of items.</p>


                        <p>To account for this dependency, we can consider either the
                            <span class="newword">worst case</span> run time analysis or the
                            <span class="newword">average case</span> run time analysis of an algorithm.
                            For a worst case run time analysis, we consider all possible problems of size n
                            and look at the <b>longest</b> possible run time for all such problems.
                            For an average case analysis, we consider all possible problems of size n
                            and look at the <b>average</b> of the run times for all such problems.
                            Usually, the average case analysis assumes that all problems of size n
                            are equally likely to be encountered, although this is not always realistic&mdash;or
                            even possible in the case where there is an infinite number of different
                            problems of a given size.</p>


                        <p>In many cases, the average and the worst case run times are the same to within a
                            constant multiple.  This means that as far as asymptotic analysis is concerned, they
                            are the same.  That is, if the average case run time is O(f(n)) or Θ(f(n)), then
                            so is the worst case.  However, later in the book, we will encounter a few cases where
                            the average and worst case asymptotic analyses differ.</p>


                        <p>It is also possible to talk about <span class="newcode">best case</span> run time
                            analysis, which looks at the <b>shortest</b> possible run time for all inputs
                            of a given size.  However, a best case analysis is only occasionally useful.</p>





                        <p>So, what do you really have to know about analysis of algorithms to read the rest
                            of this book?  We will not do any rigorous mathematical analysis, but you should be
                            able to follow informal discussion of simple cases such as the examples that we
                            have looked at in this section.  Most important, though, you should have a feeling
                            for exactly what it means to say that the running time of an algorithm is
                            O(f(n)) or Θ(f(n)) for some common functions f(n).  The main point is
                            that these notations do not tell you anything about the actual numerical value of
                            the running time of the algorithm for any particular case.  They do not tell you
                            anything at all about the running time for small values of n.  What they do tell
                            you is something about the <span class="newword">rate of growth</span> of the running time
                            as the size of the problem increases.</p>


                        <p>Suppose you compare two algorithms that solve the same problem.  The run time of
                            one algorithm is Θ(n<sup>2</sup>), while the run time of the second algorithm
                            is Θ(n<sup>3</sup>).  What does this tell you?  If you want to know which
                            algorithm will be faster for some particular problem of size, say, 100, nothing
                            is certain.  As far as you can tell just from the asymptotic analysis, either algorithm
                            could be faster for that particular case&mdash;or in <b>any</b> particular case.
                            But what you can say for sure is that if you look at larger and larger
                            problems, you will come to a point where the Θ(n<sup>2</sup>) algorithm
                            is faster than the Θ(n<sup>3</sup>) algorithm.  Furthermore, as you continue
                            to increase the problem size, the relative advantage of the Θ(n<sup>2</sup>)
                            algorithm will continue to grow.  There will be values of n for which the
                            Θ(n<sup>2</sup>) algorithm is a thousand times faster, a million times
                            faster, a billion times faster, and so on.  This is because for any positive
                            constants a and b, the function a*n<sup>3</sup> <b>grows faster</b> than
                            the function b*n<sup>2</sup> as n gets larger. (Mathematically, the limit of the ratio
                            of a*n<sup>3</sup> to b*n<sup>2</sup> is infinite as n approaches infinity.)</p>


                        <p>This means that for "large" problems, a Θ(n<sup>2</sup>) algorithm will
                            definitely be faster than a Θ(n<sup>3</sup>) algorithm. You just don't
                            know&mdash;based on the asymptotic analysis alone&mdash;exactly how large "large" has
                            to be.  In practice, in fact, it is likely that the Θ(n<sup>2</sup>)
                            algorithm will be faster even for fairly small values of&nbsp;n, and absent other
                            information you would generally prefer a Θ(n<sup>2</sup>) algorithm
                            to a Θ(n<sup>3</sup>) algorithm.</p>


                        <p>So, to understand and apply asymptotic analysis, it is essential to have some
                            idea of the rates of growth of some common functions.  For the power functions
                            n, n<sup>2</sup>, n<sup>3</sup>, n<sup>4</sup>,&nbsp;..., the larger the
                            exponent, the greater the rate of growth of the function.  Exponential functions
                            such as 2<sup>n</sup> and 10<sup>n</sup>, where the n is in the exponent, have
                            a growth rate that is faster than that of any power function.  In fact,
                            exponential functions grow so quickly that an algorithm whose run time grows
                            exponentially is almost certainly impractical even for relatively modest
                            values of n, because the running time is just too long.  Another function that
                            often turns up in asymptotic analysis is the logarithm function, log(n).
                            There are actually many different logarithm functions, but the one that
                            is usually used in computer science is the so-called logarithm to the
                            base two, which is defined by the fact that log(2<sup>x</sup>)&nbsp;=&nbsp;x for
                            any number&nbsp;x.  (Usually, this function is written log<sub>2</sub>(n),
                            but I will leave out the subscript 2, since I will only use the base-two logarithm
                            in this book.)  The logarithm function grows very slowly.  The growth
                            rate of log(n) is much smaller than the growth rate of n.  The growth rate
                            of n*log(n) is a little larger than the growth rate of n, but much smaller
                            than the growth rate of n<sup>2</sup>.  The following table should help you
                            understand the differences among the rates of growth of various functions:</p>


                        <p align="center">
                            <img src="./images/rates-of-growth.png" width="555" height="156" alt="Table of Rates of Growth of Various Functions"></p>


                        <p>The reason that log(n) shows up so often is because of its association
                            with multiplying and dividing by two:  Suppose you start with the number
                            n and divide it by 2, then divide by 2 again, and so on, until you get
                            a number that is less than or equal to 1.  Then the number of divisions
                            is equal (to the nearest integer) to log(n).</p>


                        <p>As an example, consider the binary search algorithm from <a href="ch07-05-SearchingAndSorting.html">Subsection&nbsp;7.5.1</a>.
                            This algorithm searches for an item in a sorted array.  The problem size, n, can be
                            taken to be the length of the array.  Each step in the binary search algorithm
                            divides the number of items still under consideration by&nbsp;2, and the algorithm
                            stops when the number of items under consideration is less than or equal to&nbsp;1
                            (or sooner).  It follows that the number of steps for an array of length n
                            is at most log(n).  This means that the worst-case run time for binary search
                            is Θ(log(n)).  (The average case run time is also Θ(log(n)).)
                            By comparison, the linear search algorithm, which was also presented in
                            <a href="ch07-05-SearchingAndSorting.html">Subsection&nbsp;7.5.1</a> has a run time that is Θ(n).
                            The Θ notation gives us a quantitative way to express and to understand
                            the fact that binary search is "much faster" than linear search.</p>


                        <p>In binary search, each step of the algorithm divides the problem size by 2.
                            It often happens that some operation in an algorithm (not necessarily a single step)
                            divides the problem size by 2.  Whenever that happens, the logarithm function
                            is likely to show up in an asymptotic analysis of the run time of the
                            algorithm.</p>


                        <p>Analysis of Algorithms is a large, fascinating field.  We will only use
                            a few of the most basic ideas from this field, but even those can be very helpful
                            for understanding the differences among algorithms.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="ch08-04-AssertionsAnnotations.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="ch08-06-Exercises.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="ch08-04-AssertionsAnnotations.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="ch08-06-Exercises.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="ferris.js"></script>


    </body>
</html>
